{
  "permissions": {
    "allow": [
      "Bash(python:*)",
      "Bash(\"F:\\python\\python.exe\" -c \"import PIL; print(''Pillow OK'')\")",
      "Bash(psql:*)",
      "Bash(del:*)",
      "Bash(rm:*)",
      "Bash(curl:*)",
      "Bash(mkdir:*)",
      "Bash(cp:*)",
      "WebSearch",
      "Bash(\"F:\\PostgreSQL\\bin\\psql.exe\" -U talon -d talon -f create_feedback_table.sql)",
      "Bash(\"F:\\python\\python.exe\" generate_test_data.py)",
      "Bash(\"F:\\python\\python.exe\" -m pip install pandas openpyxl xlrd)",
      "Bash(\"F:\\python\\python.exe\" simple_excel_reader.py)",
      "Bash(\"F:\\python\\python.exe\" -c \"\nimport openpyxl\ntry:\n    wb = openpyxl.load_workbook(''uploads/20250817_174631_Cartel1.xls'')\n    print(''File Excel aperto con successo'')\n    print(''Fogli disponibili:'', wb.sheetnames)\n    for sheet_name in wb.sheetnames:\n        ws = wb[sheet_name]\n        print(f''\\n--- Foglio: {sheet_name} ---'')\n        print(f''Righe: {ws.max_row}, Colonne: {ws.max_column}'')\n        print(''Headers (prima riga):'')\n        for col in range(1, min(ws.max_column + 1, 11)):\n            cell_value = ws.cell(row=1, column=col).value\n            print(f''  Col {col}: {cell_value}'')\n        print(''Dati esempi (riga 2):'')\n        for col in range(1, min(ws.max_column + 1, 6)):\n            cell_value = ws.cell(row=2, column=col).value\n            print(f''  Col {col}: {cell_value}'')\n    wb.close()\nexcept Exception as e:\n    print(f''Errore: {e}'')\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nimport xlrd\ntry:\n    wb = xlrd.open_workbook(''uploads/20250817_174631_Cartel1.xls'')\n    print(''File Excel .xls aperto con successo'')\n    print(''Fogli disponibili:'', wb.sheet_names())\n    \n    for sheet_name in wb.sheet_names():\n        ws = wb.sheet_by_name(sheet_name)\n        print(f''\\n--- Foglio: {sheet_name} ---'')\n        print(f''Righe: {ws.nrows}, Colonne: {ws.ncols}'')\n        \n        if ws.nrows > 0:\n            print(''Headers (prima riga):'')\n            for col in range(min(ws.ncols, 10)):\n                cell_value = ws.cell_value(0, col)\n                print(f''  Col {col+1}: {cell_value}'')\n        \n        if ws.nrows > 1:\n            print(''Dati esempi (riga 2):'')\n            for col in range(min(ws.ncols, 6)):\n                cell_value = ws.cell_value(1, col)\n                print(f''  Col {col+1}: {cell_value}'')\n        \n        if ws.nrows > 2:\n            print(''Dati esempi (riga 3):'')\n            for col in range(min(ws.ncols, 6)):\n                cell_value = ws.cell_value(2, col)\n                print(f''  Col {col+1}: {cell_value}'')\n                \nexcept ImportError:\n    print(''xlrd non installato'')\nexcept Exception as e:\n    print(f''Errore: {e}'')\n\")",
      "Bash(\"F:\\python\\python.exe\" import_server.py)",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test completo della pulizia dati per attività\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST PULIZIA DATI ATTIVITA ==='')\n\n# Analizza il file\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\n\nif analysis:\n    print(''Analisi completata. Cleaning data...'')\n    \n    # Pulisci e normalizza i dati\n    df_clean = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'')\n    \n    print(f''\\nDATI PULITI - Shape: {df_clean.shape}'')\n    print(f''Colonne: {list(df_clean.columns)}'')\n    \n    if not df_clean.empty:\n        print(''\\n=== PRIMA RIGA ESEMPIO ==='')\n        first_row = df_clean.iloc[0]\n        for col, val in first_row.items():\n            print(f''{col}: {val} ({type(val).__name__})'')\n        \n        print(''\\n=== STATISTICHE COLONNE CHIAVE ==='')\n        if ''ente_svolgimento_id'' in df_clean.columns:\n            non_null_enti = df_clean[''ente_svolgimento_id''].notna().sum()\n            print(f''Enti riconosciuti: {non_null_enti}/{len(df_clean)} ({non_null_enti/len(df_clean)*100:.1f}%)'')\n        \n        if ''tipologia_id'' in df_clean.columns:\n            non_null_tipi = df_clean[''tipologia_id''].notna().sum()\n            print(f''Tipologie riconosciute: {non_null_tipi}/{len(df_clean)} ({non_null_tipi/len(df_clean)*100:.1f}%)'')\n            \n            # Mostra i valori delle tipologie\n            unique_tipi = df_clean[''tipologia_id''].dropna().unique()\n            print(f''ID tipologie trovate: {unique_tipi}'')\nelse:\n    print(''Errore analisi file'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test del matching migliorato degli enti\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST MATCHING ENTI MIGLIORATO ==='')\n\n# Test specifico per il Policlinico Celio\ntest_names = [\n    ''POLICLINICO MILITARE \"\"CELIO\"\"'',\n    ''POLICLINICO MILITARE CELIO'',\n    ''POLICLINICO CELIO'',\n    ''Policlinico Militare di Roma Celio''\n]\n\nfor name in test_names:\n    ente_id = importer._lookup_ente_militare_id(name)\n    print(f''Input: \"\"{name}\"\" -> ID: {ente_id}'')\n\n# Test completo pulizia dati\nprint(''\\n=== TEST PULIZIA COMPLETA ==='')\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_clean = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'')\n\nif not df_clean.empty:\n    print(f''Shape: {df_clean.shape}'')\n    \n    # Statistiche\n    enti_trovati = df_clean[''ente_svolgimento_id''].notna().sum()\n    tipi_trovati = df_clean[''tipologia_id''].notna().sum()\n    \n    print(f''Enti riconosciuti: {enti_trovati}/{len(df_clean)} ({enti_trovati/len(df_clean)*100:.1f}%)'')\n    print(f''Tipologie riconosciute: {tipi_trovati}/{len(df_clean)} ({tipi_trovati/len(df_clean)*100:.1f}%)'')\n    \n    # Prima riga di esempio\n    print(''\\n=== PRIMA RIGA PULITA ==='')\n    row = df_clean.iloc[0]\n    for col in [''ente_svolgimento_id'', ''tipologia_id'', ''data_inizio'', ''descrizione'', ''quantita'']:\n        if col in row:\n            print(f''{col}: {row[col]}'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test della serializzazione completa\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST SERIALIZZAZIONE COMPLETA ==='')\n\n# Analizza e pulisci dati\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_clean = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'')\n\nprint(f''Dati puliti: {df_clean.shape}'')\n\n# Test di serializzazione delle prime righe\nprint(''\\n=== TEST SERIALIZZAZIONE PREVIEW ==='')\ntry:\n    sample_data = df_clean.head(3).to_dict(''records'')\n    serialized_sample = []\n    \n    for row in sample_data:\n        serialized_row = {}\n        for key, value in row.items():\n            serialized_row[key] = importer._serialize_value(value)\n        serialized_sample.append(serialized_row)\n    \n    print(''Serializzazione completata con successo!'')\n    print(f''Esempio prima riga serializzata:'')\n    for key, value in serialized_sample[0].items():\n        print(f''  {key}: {value} ({type(value).__name__})'')\n        \n    # Test specifico per valori NaT\n    import pandas as pd\n    nat_value = pd.NaT\n    serialized_nat = importer._serialize_value(nat_value)\n    print(f''\\nTest NaT: {nat_value} -> {serialized_nat} ({type(serialized_nat).__name__})'')\n    \nexcept Exception as e:\n    print(f''Errore serializzazione: {e}'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nimport requests\nimport json\n\n# Test dell''endpoint di anteprima\nprint(''=== TEST ENDPOINT ANTEPRIMA ==='')\n\ntry:\n    # Simula richiesta di anteprima\n    url = ''http://127.0.0.1:5001/preview_data/Foglio1''\n    \n    # Prima assicurati che ci sia un file analizzato (simula upload)\n    from data_importer import TalonDataImporter\n    importer = TalonDataImporter()\n    if importer.connect_to_database():\n        analysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\n        importer.close_connection()\n        print(''File analizzato con successo'')\n    \n    # Test di serializzazione locale\n    importer = TalonDataImporter()\n    if importer.connect_to_database():\n        df_clean = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'')\n        \n        print(f''DataFrame shape: {df_clean.shape}'')\n        print(''Colonne:'', list(df_clean.columns))\n        \n        # Test serializzazione prima riga\n        first_row = df_clean.iloc[0].to_dict()\n        serialized = {}\n        for key, value in first_row.items():\n            serialized[key] = importer._serialize_value(value)\n        \n        print(''\\nPrima riga serializzata:'')\n        for k, v in serialized.items():\n            print(f''  {k}: {v} ({type(v).__name__})'')\n        \n        # Test JSON\n        json_str = json.dumps(serialized)\n        print(f''\\nJSON serializzazione: OK ({len(json_str)} chars)'')\n        \n        importer.close_connection()\n        \nexcept Exception as e:\n    print(f''Errore: {e}'')\n    import traceback\n    traceback.print_exc()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test delle due modalità di pulizia dati\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST MODALITA ANTEPRIMA vs IMPORTAZIONE ==='')\n\n# Analizza il file\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\n\n# Test modalità ANTEPRIMA (for_preview=True)\nprint(''\\n--- MODALITA ANTEPRIMA (nomi leggibili) ---'')\ndf_preview = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=True)\nprint(f''Colonne anteprima: {list(df_preview.columns)}'')\nprint(f''Shape: {df_preview.shape}'')\nif not df_preview.empty:\n    print(''Prima riga anteprima:'')\n    row = df_preview.iloc[0]\n    for col in [''ente_svolgimento'', ''tipologia_attivita'', ''data_inizio'', ''descrizione'', ''quantita'']:\n        if col in row:\n            print(f''  {col}: {row[col]}'')\n\n# Test modalità IMPORTAZIONE (for_preview=False)\nprint(''\\n--- MODALITA IMPORTAZIONE (con ID) ---'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\nprint(f''Colonne importazione: {list(df_import.columns)}'')\nprint(f''Shape: {df_import.shape}'')\nif not df_import.empty:\n    print(''Prima riga importazione:'')\n    row = df_import.iloc[0]\n    for col in [''ente_svolgimento_id'', ''tipologia_id'', ''data_inizio'', ''descrizione'', ''quantita'']:\n        if col in row:\n            print(f''  {col}: {row[col]}'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test del nuovo mapping medicina curativa\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST NUOVO MAPPING MEDICINA CURATIVA ==='')\n\n# Test funzione mapping tipo intervento\ntest_descriptions = [\n    ''INTERVENTI DI CHIRURGIA PLASTICA'',\n    ''INTERVENTI DI CHIRURGIA GENERALE'', \n    ''INTERVENTI DI ORTOPEDIA'',\n    ''INTERVENTI DI UROLOGIA'',\n    ''ATTIVITA\\'' CHIRURGICA''\n]\n\nprint(''\\n--- TEST MAPPING TIPO INTERVENTO ---'')\nfor desc in test_descriptions:\n    mapped = importer._map_tipo_intervento(desc)\n    print(f''Input: \"\"{desc}\"\" -> Output: \"\"{mapped}\"\"'')\n\n# Test analisi e pulizia dati\nprint(''\\n--- TEST MODALITA ANTEPRIMA ---'')\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_preview = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=True)\n\nif not df_preview.empty:\n    print(f''Colonne anteprima: {list(df_preview.columns)}'')\n    print(''\\nPrima riga anteprima:'')\n    row = df_preview.iloc[0]\n    for col in [''ente_svolgimento'', ''tipologia_attivita'', ''descrizione'', ''tipo_intervento'', ''data_inizio'', ''quantita'']:\n        if col in row:\n            print(f''  {col}: {row[col]}'')\n\nprint(''\\n--- TEST MODALITA IMPORTAZIONE ---'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nif not df_import.empty:\n    print(f''Colonne importazione: {list(df_import.columns)}'')\n    print(''\\nPrima riga importazione:'')\n    row = df_import.iloc[0]\n    for col in [''ente_svolgimento_id'', ''tipologia_id'', ''descrizione'', ''data_inizio'', ''quantita'']:\n        if col in row:\n            print(f''  {col}: {row[col]}'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test completo di tutte le funzionalità\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST FUNZIONALITA COMPLETE ==='')\n\n# Test analisi e pulizia dati\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_preview = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=True)\n\nprint(''\\n--- ANTEPRIMA (CON DESCRIZIONI INTELLIGENTI) ---'')\nprint(f''Colonne ordinate: {list(df_preview.columns)}'')\nif not df_preview.empty:\n    print(''\\nPrima riga completa:'')\n    row = df_preview.iloc[0]\n    for col in df_preview.columns:\n        print(f''  {col}: {row[col]}'')\n\nprint(''\\n--- MODALITA IMPORTAZIONE ---'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nif not df_import.empty:\n    print(''\\nPrima riga importazione:'')\n    row = df_import.iloc[0]\n    key_cols = [''ente_svolgimento_id'', ''tipologia_id'', ''descrizione'', ''data_inizio'', ''quantita'']\n    for col in key_cols:\n        if col in row:\n            print(f''  {col}: {row[col]}'')\n\n# Test mapping tipo interventi\nprint(''\\n--- TEST MAPPING COMPLETO ---'')\ntest_descriptions = [\n    ''INTERVENTI DI CHIRURGIA PLASTICA'',\n    ''INTERVENTI DI ORTOPEDIA'', \n    ''INTERVENTI DI UROLOGIA'',\n    ''INTERVENTI DI GINECOLOGIA''\n]\n\nfor desc in test_descriptions:\n    tipo_intervento = importer._map_tipo_intervento(desc)\n    descrizione_generalizzata = importer._generalize_description(tipo_intervento)\n    print(f''  \"\"{desc}\"\" -> \"\"{tipo_intervento}\"\" -> \"\"{descrizione_generalizzata}\"\"'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test per verificare che vengano mostrate tutte le righe\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST ANTEPRIMA COMPLETA ==='')\n\n# Analizza e pulisci dati\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_preview = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=True)\n\nprint(f''Numero totale righe nel file: {len(df_preview)}'')\nprint(f''Colonne: {list(df_preview.columns)}'')\n\n# Verifica alcune righe di esempio\nprint(''\\n--- PRIME 3 RIGHE ---'')\nfor i in range(min(3, len(df_preview))):\n    row = df_preview.iloc[i]\n    print(f''Riga {i+1}:'')\n    print(f''  Ente: {row[\"\"ente_svolgimento\"\"]}'')\n    print(f''  Descrizione: {row[\"\"descrizione\"\"]}'') \n    print(f''  Tipo Intervento: {row[\"\"tipo_intervento\"\"]}'')\n    print(f''  Quantità: {row[\"\"quantita\"\"]}'')\n    print()\n\nprint(f''--- ULTIME 2 RIGHE ---'')\nfor i in range(max(0, len(df_preview)-2), len(df_preview)):\n    row = df_preview.iloc[i]\n    print(f''Riga {i+1}:'')\n    print(f''  Ente: {row[\"\"ente_svolgimento\"\"]}'')\n    print(f''  Descrizione: {row[\"\"descrizione\"\"]}'') \n    print(f''  Tipo Intervento: {row[\"\"tipo_intervento\"\"]}'')\n    print(f''  Quantità: {row[\"\"quantita\"\"]}'')\n    print()\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -m pip install xlrd)",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test rapido del sistema\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST SISTEMA COMPLETO ==='')\n\ntry:\n    # Analizza e pulisci dati\n    analysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\n    \n    if analysis:\n        print(''Analisi file: OK'')\n        df_preview = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=True)\n        \n        print(f''Righe totali: {len(df_preview)}'')\n        print(f''Colonne: {list(df_preview.columns)}'')\n        \n        # Test serializzazione (problema drag & drop)\n        import json\n        test_row = df_preview.iloc[0].to_dict()\n        serialized = {}\n        for key, value in test_row.items():\n            serialized[key] = importer._serialize_value(value)\n        \n        json_test = json.dumps(serialized)\n        print(''Test serializzazione JSON: OK'')\n        print(f''Lunghezza JSON prima riga: {len(json_test)} chars'')\n        \n        print(''\\nSistema pronto per test interfaccia web.'')\n        print(''Vai su: http://127.0.0.1:5001'')\n        \n    else:\n        print(''Errore analisi file'')\n        \nexcept Exception as e:\n    print(f''Errore: {e}'')\n    import traceback\n    traceback.print_exc()\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test rapido del sistema  \nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST SISTEMA COMPLETO ==='')\n\ntry:\n    # Analizza e pulisci dati\n    analysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\n    \n    if analysis:\n        print(''Analisi file: OK'')\n        df_preview = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=True)\n        \n        print(f''Righe totali: {len(df_preview)}'')\n        print(f''Colonne: {list(df_preview.columns)}'')\n        \n        # Test prima e ultima riga\n        print(''\\n=== PRIMA RIGA ==='')\n        row = df_preview.iloc[0]\n        for col in [''ente_svolgimento'', ''tipologia_attivita'', ''descrizione'']:\n            if col in row:\n                print(f''  {col}: {row[col]}'')\n        \n        print(f''\\n=== ULTIMA RIGA ==='')\n        last_row = df_preview.iloc[-1]\n        for col in [''ente_svolgimento'', ''tipologia_attivita'', ''descrizione'']:\n            if col in last_row:\n                print(f''  {col}: {last_row[col]}'')\n        \n        print(''\\nSistema pronto per test interfaccia web.'')\n        print(''Il server è in esecuzione su: http://127.0.0.1:5001'')\n        \n    else:\n        print(''Errore analisi file'')\n        \nexcept Exception as e:\n    print(f''Errore: {e}'')\n    import traceback\n    traceback.print_exc()\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Debug del problema importazione\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== DEBUG PROBLEMA IMPORTAZIONE ==='')\n\n# Analizza e pulisci dati per modalità importazione (con ID)\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nprint(f''DataFrame per importazione - Shape: {df_import.shape}'')\nprint(f''Colonne: {list(df_import.columns)}'')\n\nif not df_import.empty:\n    print(''\\n=== PRIMA RIGA MODALITÀ IMPORTAZIONE ==='')\n    row = df_import.iloc[0]\n    for col in df_import.columns:\n        value = row[col]\n        print(f''  {col}: {value} ({type(value).__name__})'')\n    \n    # Verifica valori None/NaN critici\n    print(''\\n=== VERIFICA VALORI CRITICI ==='')\n    required_cols = [''ente_svolgimento_id'', ''tipologia_id'']\n    for col in required_cols:\n        if col in df_import.columns:\n            null_count = df_import[col].isnull().sum()\n            valid_count = df_import[col].notna().sum()\n            print(f''  {col}: {valid_count} validi, {null_count} nulli'')\n            \n            if valid_count > 0:\n                unique_vals = df_import[col].dropna().unique()\n                print(f''    Valori unici: {unique_vals[:5]}'')\n    \n    # Test controllo esistenti\n    print(''\\n=== TEST CONTROLLO RECORD ESISTENTI ==='')\n    target_table = ''attivita''\n    df_new, existing_records = importer.check_existing_data(df_import, target_table)\n    \n    print(f''Record nuovi da importare: {len(df_new)}'')\n    print(f''Record già esistenti: {len(existing_records)}'')\n    \n    if len(df_new) == 0 and len(existing_records) == 0:\n        print(''\\n⚠️ PROBLEMA: Nessun record nuovo e nessun esistente trovato'')\n        print(''Questo indica un problema nel controllo dei duplicati o nei dati'')\n        \n        # Verifica se i dati hanno chiavi primarie valide\n        if ''id'' in df_import.columns:\n            print(f''Colonna ID presente: {df_import[\"\"id\"\"].notna().sum()} valori validi'')\nelse:\n    print(''⚠️ DataFrame vuoto dopo pulizia dati'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\nimport pandas as pd\n\n# Debug del controllo esistenti\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== DEBUG CONTROLLO RECORD ESISTENTI ==='')\n\n# Prepara dati di test\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nif not df_import.empty:\n    # Test prima riga\n    first_row = df_import.iloc[0]\n    ente_id = first_row[''ente_svolgimento_id'']\n    tipologia_id = first_row[''tipologia_id'']\n    data_inizio = first_row[''data_inizio'']\n    \n    print(f''Test con: ente_id={ente_id}, tipologia_id={tipologia_id}, data_inizio={data_inizio}'')\n    \n    # Test query diretta\n    try:\n        with importer.db_connection.cursor() as cur:\n            print(''\\n=== TEST QUERY DIRETTA ==='')\n            cur.execute(''''''\n                SELECT id, ente_svolgimento_id, tipologia_id, data_inizio \n                FROM attivita \n                WHERE ente_svolgimento_id = %s AND tipologia_id = %s AND data_inizio = %s\n            '''''', (ente_id, tipologia_id, data_inizio))\n            \n            results = cur.fetchall()\n            print(f''Record trovati nel DB: {len(results)}'')\n            for result in results:\n                print(f''  ID: {result[0]}, Ente: {result[1]}, Tipologia: {result[2]}, Data: {result[3]}'')\n            \n            # Verifica tutti i record nella tabella attivita\n            print(''\\n=== VERIFICA TABELLA ATTIVITA ==='')\n            cur.execute(''SELECT COUNT(*) FROM attivita'')\n            total_count = cur.fetchone()[0]\n            print(f''Totale record in tabella attivita: {total_count}'')\n            \n            if total_count > 0:\n                cur.execute(''SELECT id, ente_svolgimento_id, tipologia_id, data_inizio FROM attivita LIMIT 5'')\n                sample_records = cur.fetchall()\n                print(''Prime 5 righe in tabella:'')\n                for record in sample_records:\n                    print(f''  ID: {record[0]}, Ente: {record[1]}, Tipologia: {record[2]}, Data: {record[3]}'')\n            \n    except Exception as e:\n        print(f''Errore query diretta: {e}'')\n        \n        # Reset connessione se necessario\n        importer.close_connection()\n        importer.connect_to_database()\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test del fix per numpy types\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST FIX NUMPY TYPES ==='')\n\n# Prepara dati\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nif not df_import.empty:\n    print(f''DataFrame shape: {df_import.shape}'')\n    \n    # Test controllo esistenti con la correzione\n    print(''\\n=== TEST CONTROLLO ESISTENTI CORRETTO ==='')\n    df_new, existing_records = importer.check_existing_data(df_import, ''attivita'')\n    \n    print(f''Record nuovi da importare: {len(df_new)}'')\n    print(f''Record già esistenti: {len(existing_records)}'')\n    \n    if len(df_new) > 0:\n        print(f''✅ SUCCESSO: Trovati {len(df_new)} nuovi record da importare'')\n        \n        # Mostra esempio di un nuovo record\n        print(''\\nEsempio nuovo record:'')\n        first_new = df_new.iloc[0] if not df_new.empty else None\n        if first_new is not None:\n            for col in [''ente_svolgimento_id'', ''tipologia_id'', ''data_inizio'', ''descrizione'', ''quantita'']:\n                if col in first_new:\n                    print(f''  {col}: {first_new[col]}'')\n    \n    if len(existing_records) > 0:\n        print(f''📋 Trovati {len(existing_records)} record già esistenti'')\n        \n    if len(df_new) == 0 and len(existing_records) == 0:\n        print(''⚠️ Ancora nessun record trovato - verifichiamo il database'')\n        \n        # Verifica diretta del database\n        with importer.db_connection.cursor() as cur:\n            cur.execute(''SELECT COUNT(*) FROM attivita'')\n            count = cur.fetchone()[0]\n            print(f''Totale record in tabella attivita: {count}'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test finale del fix\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST FINALE CORREZIONE ==='')\n\n# Test controllo database attivita\nwith importer.db_connection.cursor() as cur:\n    cur.execute(''SELECT COUNT(*) FROM attivita'')\n    existing_count = cur.fetchone()[0]\n    print(f''Record esistenti in tabella attivita: {existing_count}'')\n\n# Prepara dati\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nprint(f''Record da processare dal file Excel: {len(df_import)}'')\n\n# Test controllo esistenti\nprint(''\\n=== CONTROLLO RECORD ESISTENTI ==='')\ndf_new, existing_records = importer.check_existing_data(df_import, ''attivita'')\n\nprint(f''Record nuovi da importare: {len(df_new)}'')\nprint(f''Record già esistenti nel DB: {len(existing_records)}'')\n\nif len(df_new) > 0:\n    print(f''✅ SUCCESSO: {len(df_new)} nuovi record pronti per importazione'')\nelif len(existing_records) > 0:\n    print(f''📋 INFO: Tutti i {len(existing_records)} record sono già presenti nel database'')\nelse:\n    print(''❓ ANOMALIA: Nessun record nuovo né esistente trovato'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test finale correzione completa\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST FINALE SISTEMAZIONE COMPLETA ==='')\n\n# Verifica database\nwith importer.db_connection.cursor() as cur:\n    cur.execute(''SELECT COUNT(*) FROM attivita'')\n    existing_count = cur.fetchone()[0]\n    print(f''Record esistenti in tabella attivita: {existing_count}'')\n\n# Prepara dati Excel\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nprint(f''Record da processare dal file Excel: {len(df_import)}'')\n\n# Mostra prima riga per debug\nif not df_import.empty:\n    print(''\\nPrima riga dati:'')\n    row = df_import.iloc[0]\n    for col in [''ente_svolgimento_id'', ''tipologia_id'', ''data_inizio'', ''descrizione'', ''quantita'']:\n        if col in row:\n            print(f''  {col}: {row[col]} ({type(row[col]).__name__})'')\n\n# Test controllo esistenti\nprint(''\\n=== CONTROLLO RECORD ESISTENTI ==='')\ndf_new, existing_records = importer.check_existing_data(df_import, ''attivita'')\n\nprint(f''✅ Record nuovi da importare: {len(df_new)}'')\nprint(f''📋 Record già esistenti nel DB: {len(existing_records)}'')\n\nif len(df_new) > 0:\n    print(f''\\n🎯 PRONTO PER IMPORTAZIONE: {len(df_new)} nuovi record'')\nelif len(existing_records) > 0:\n    print(f''\\n📊 RISULTATO: Tutti i {len(existing_records)} record sono già nel database'')\nelse:\n    print(f''\\n❌ PROBLEMA: Nessun record processato correttamente'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test finale con gestione corretta result\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST FINALE SISTEMAZIONE COMPLETA ==='')\n\n# Verifica database (correzione KeyError)\nwith importer.db_connection.cursor() as cur:\n    cur.execute(''SELECT COUNT(*) FROM attivita'')\n    result = cur.fetchone()\n    existing_count = result[0] if result else 0\n    print(f''Record esistenti in tabella attivita: {existing_count}'')\n\n# Prepara dati Excel\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nprint(f''Record da processare dal file Excel: {len(df_import)}'')\n\n# Test controllo esistenti\nprint(''\\n=== CONTROLLO RECORD ESISTENTI ==='')\ndf_new, existing_records = importer.check_existing_data(df_import, ''attivita'')\n\nprint(f''✅ Record nuovi da importare: {len(df_new)}'')\nprint(f''📋 Record già esistenti nel DB: {len(existing_records)}'')\n\nif len(df_new) > 0:\n    print(f''\\n🎯 PRONTO PER IMPORTAZIONE: {len(df_new)} nuovi record'')\n    print(''Il sistema può ora procedere con l\\''importazione.'')\nelif len(existing_records) > 0:\n    print(f''\\n📊 RISULTATO: Tutti i {len(existing_records)} record sono già nel database'')\n    print(''Non è necessaria nessuna importazione.'')\nelse:\n    print(f''\\n❌ PROBLEMA: Nessun record processato correttamente'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test isolato connessione database\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST CONNESSIONE DATABASE ==='')\n\ntry:\n    with importer.db_connection.cursor() as cur:\n        cur.execute(''SELECT COUNT(*) FROM attivita'')\n        result = cur.fetchone()\n        print(f''Tipo result: {type(result)}'')\n        print(f''Contenuto result: {result}'')\n        \n        if isinstance(result, dict):\n            print(''Result è un dizionario'')\n            count = result.get(''count'', 0)\n        elif isinstance(result, (tuple, list)):\n            print(''Result è una tupla/lista'')\n            count = result[0] if result and len(result) > 0 else 0\n        else:\n            print(f''Result è tipo sconosciuto: {type(result)}'')\n            count = 0\n            \n        print(f''Count finale: {count}'')\n        \n        # Test query semplice\n        cur.execute(''SELECT id, nome FROM tipologie_attivita LIMIT 1'')\n        tip_result = cur.fetchone()\n        print(f''\\nTest tipologie_attivita:'')\n        print(f''Tipo: {type(tip_result)}'')\n        print(f''Contenuto: {tip_result}'')\n        \nexcept Exception as e:\n    print(f''Errore test database: {e}'')\n    import traceback\n    traceback.print_exc()\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test controllo esistenti con database funzionante\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST CONTROLLO RECORD ESISTENTI ==='')\n\n# Verifica database\nwith importer.db_connection.cursor() as cur:\n    cur.execute(''SELECT COUNT(*) FROM attivita'')\n    result = cur.fetchone()\n    existing_count = result[''count'']\n    print(f''Record esistenti in tabella attivita: {existing_count}'')\n\n# Prepara dati Excel\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nprint(f''Record da processare dal file Excel: {len(df_import)}'')\n\n# Test controllo esistenti\ndf_new, existing_records = importer.check_existing_data(df_import, ''attivita'')\n\nprint(f''✅ Record nuovi da importare: {len(df_new)}'')\nprint(f''📋 Record già esistenti nel DB: {len(existing_records)}'')\n\nif len(df_new) > 0:\n    print(f''\\n🎯 PRONTO PER IMPORTAZIONE: {len(df_new)} nuovi record'')\n    print(''Procedi con l\\''importazione nell\\''interfaccia web.'')\nelif len(existing_records) > 0:\n    print(f''\\n📊 TUTTI I RECORD SONO GIÀ NEL DATABASE'')\n    print(f''I {len(existing_records)} record dal file Excel sono già presenti.'')\n    print(''Non è necessaria alcuna importazione.'')\nelse:\n    print(f''\\n❓ VERIFICA NECESSARIA: Nessun record nuovo o esistente trovato'')\n\n# Mostra alcuni record esistenti se presenti\nif existing_records:\n    print(f''\\n--- ESEMPI RECORD ESISTENTI ---'')\n    for i, rec in enumerate(existing_records[:3]):\n        print(f''Record {i+1}:'')\n        excel_data = rec[''excel_data'']\n        print(f''  Excel: Ente {excel_data.get(\"\"ente_svolgimento_id\"\")}, Data {excel_data.get(\"\"data_inizio\"\")}'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test controllo esistenti senza emoji\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST CONTROLLO RECORD ESISTENTI ==='')\n\n# Verifica database\nwith importer.db_connection.cursor() as cur:\n    cur.execute(''SELECT COUNT(*) FROM attivita'')\n    result = cur.fetchone()\n    existing_count = result[''count'']\n    print(f''Record esistenti in tabella attivita: {existing_count}'')\n\n# Prepara dati Excel\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_import = importer.clean_and_normalize_data(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'', for_preview=False)\n\nprint(f''Record da processare dal file Excel: {len(df_import)}'')\n\n# Test controllo esistenti\ndf_new, existing_records = importer.check_existing_data(df_import, ''attivita'')\n\nprint(f''Record nuovi da importare: {len(df_new)}'')\nprint(f''Record già esistenti nel DB: {len(existing_records)}'')\n\nif len(df_new) > 0:\n    print(f''PRONTO PER IMPORTAZIONE: {len(df_new)} nuovi record'')\n    print(''Procedi con importazione nell\\''interfaccia web.'')\nelif len(existing_records) > 0:\n    print(f''TUTTI I RECORD SONO GIA NEL DATABASE'')\n    print(f''I {len(existing_records)} record dal file Excel sono già presenti.'')\n    print(''Non è necessaria alcuna importazione.'')\nelse:\n    print(f''VERIFICA NECESSARIA: Nessun record nuovo o esistente trovato'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nimport xlrd\nimport pandas as pd\n\n# Verifica quante righe ci sono effettivamente nel file\nprint(''=== VERIFICA RIGHE TOTALI FILE EXCEL ==='')\n\ntry:\n    # Metodo 1: xlrd\n    wb = xlrd.open_workbook(''uploads/20250817_174631_Cartel1.xls'')\n    ws = wb.sheet_by_name(''Foglio1'')\n    print(f''xlrd - Righe totali: {ws.nrows}'')\n    print(f''xlrd - Colonne: {ws.ncols}'')\n    \n    # Metodo 2: pandas\n    df_raw = pd.read_excel(''uploads/20250817_174631_Cartel1.xls'', sheet_name=''Foglio1'')\n    print(f''pandas - Righe totali: {len(df_raw)}'')\n    print(f''pandas - Colonne: {len(df_raw.columns)}'')\n    \n    # Verifica se ci sono righe vuote\n    non_empty_rows = df_raw.dropna(how=''all'')\n    print(f''pandas - Righe non vuote: {len(non_empty_rows)}'')\n    \n    # Mostra prime e ultime righe\n    print(f''\\nPrime 3 righe:'')\n    for i in range(min(3, len(df_raw))):\n        print(f''  Riga {i+1}: {list(df_raw.iloc[i][:3])}'')\n    \n    print(f''\\nUltime 3 righe:'')\n    for i in range(max(0, len(df_raw)-3), len(df_raw)):\n        print(f''  Riga {i+1}: {list(df_raw.iloc[i][:3])}'')\n        \nexcept Exception as e:\n    print(f''Errore: {e}'')\n    import traceback\n    traceback.print_exc()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test del nuovo sistema analyze_all_rows\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST NUOVO SISTEMA ANALYZE_ALL_ROWS ==='')\n\n# Analizza il file\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_all = importer.analyze_all_rows(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'')\n\nprint(f''Righe totali analizzate: {len(df_all)}'')\nprint(f''Colonne: {list(df_all.columns)}'')\n\n# Statistiche status\nstatus_counts = df_all[''row_status''].value_counts()\nprint(f''\\nDistribuzione status:'')\nfor status, count in status_counts.items():\n    print(f''  {status}: {count}'')\n\n# Esempi per ogni status\nprint(f''\\n=== ESEMPI PER STATUS ==='')\nfor status in status_counts.index:\n    rows_with_status = df_all[df_all[''row_status''] == status]\n    if len(rows_with_status) > 0:\n        print(f''\\n--- {status.upper()} (esempio riga {rows_with_status.index[0]+1}) ---'')\n        row = rows_with_status.iloc[0]\n        print(f''  Issues: {row[\"\"row_issues\"\"]}'')\n        print(f''  DB exists: {row[\"\"db_exists\"\"]}'')\n        if len(row) > 5:\n            print(f''  Dati: {row.iloc[1]} | {row.iloc[2]} | {row.iloc[3]}'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test completo nuovo sistema\nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST SISTEMA COMPLETO AGGIORNATO ==='')\n\n# Test analisi completa con controllo duplicati DB\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_all = importer.analyze_all_rows(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'')\n\nprint(f''Righe totali nel file: 327'')\nprint(f''Righe analizzate: {len(df_all)}'')\n\n# Controllo manuale duplicati database (simuliamo il controllo nel server)\nduplicates_found = 0\nwith importer.db_connection.cursor() as cur:\n    for idx, row in df_all.iterrows():\n        if idx < 5:  # Test solo prime 5 righe per velocità\n            try:\n                ente_nome = row[''CHI'']\n                data_inizio = row[''IL'']\n                \n                if pd.notna(ente_nome) and pd.notna(data_inizio):\n                    ente_id = importer._lookup_ente_militare_id(str(ente_nome))\n                    tipologia_id = importer._lookup_tipologia_attivita_id(''MEDICINA CURATIVA'')\n                    \n                    if ente_id and tipologia_id:\n                        cur.execute(''''''\n                            SELECT id FROM attivita \n                            WHERE ente_svolgimento_id = %s AND tipologia_id = %s AND data_inizio = %s\n                        '''''', (ente_id, tipologia_id, importer._convert_to_python_type(data_inizio)))\n                        \n                        if cur.fetchone():\n                            duplicates_found += 1\n                            print(f''  Riga {idx+1}: DUPLICATO nel DB'')\n            except Exception as e:\n                print(f''  Riga {idx+1}: Errore controllo - {e}'')\n\nprint(f''\\nDuplicati trovati nelle prime 5 righe: {duplicates_found}'')\nprint(f''Statistiche status: {df_all[\"\"row_status\"\"].value_counts().to_dict()}'')\n\nprint(f''\\nIl sistema è pronto per test web con:'')\nprint(f''- Tutte le {len(df_all)} righe visualizzate'')\nprint(f''- Controllo duplicati vs database'')\nprint(f''- Modifica inline delle celle'')\nprint(f''- Checkbox force insert'')\nprint(f''- Drag & drop colonne'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\n# Test scalabilità con file grandi simulati\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime, timedelta\nimport random\n\nprint(''=== TEST SCALABILITÀ SISTEMA ==='')\n\n# Simula file di diverse dimensioni\ntest_sizes = [500, 1000, 5000, 10000]\n\nfor size in test_sizes:\n    print(f''\\n--- Test con {size} righe ---'')\n    \n    # Crea DataFrame di test\n    dates = [datetime(2025, 1, 1) + timedelta(days=i % 365) for i in range(size)]\n    data = {\n        ''CHI'': [''POLICLINICO MILITARE \"\"CELIO\"\"''] * size,\n        ''ATTIVITA\\'''': [''ATTIVITA\\'' CHIRURGICA''] * size, \n        ''IL'': dates,\n        ''COSA'': [''INTERVENTI DI CHIRURGIA GENERALE''] * size,\n        ''Q.TA\\'''': [random.randint(1, 10) for _ in range(size)]\n    }\n    \n    df_test = pd.DataFrame(data)\n    \n    # Test memoria e performance\n    memory_usage = df_test.memory_usage(deep=True).sum() / 1024 / 1024  # MB\n    print(f''  Memoria utilizzata: {memory_usage:.2f} MB'')\n    \n    # Test serializzazione JSON (collo di bottiglia)\n    import time\n    start = time.time()\n    \n    # Simula serializzazione come nel server\n    serialized_count = 0\n    for idx, row in df_test.head(100).iterrows():  # Test solo prime 100 per velocità\n        serialized_row = {}\n        for key, value in row.items():\n            if pd.isna(value):\n                serialized_row[key] = None\n            elif hasattr(value, ''isoformat''):\n                serialized_row[key] = value.isoformat()\n            else:\n                serialized_row[key] = str(value)\n        serialized_count += 1\n    \n    end = time.time()\n    serialization_time = (end - start) * (size / 100)  # Estrapola per tutte le righe\n    \n    print(f''  Tempo serializzazione stimato: {serialization_time:.2f} secondi'')\n    print(f''  Fattibilità: {\"\"OK\"\" if serialization_time < 30 else \"\"LENTO\"\" if serialization_time < 60 else \"\"PROBLEMATICO\"\"}'')\n    \n    # Limiti pratici browser\n    html_size_mb = (size * 10 * 50) / 1024 / 1024  # Stima: 10 colonne x 50 char per cella\n    print(f''  Dimensione HTML stimata: {html_size_mb:.2f} MB'')\n    print(f''  Browser: {\"\"OK\"\" if html_size_mb < 50 else \"\"LENTO\"\" if html_size_mb < 100 else \"\"PROBLEMATICO\"\"}'')\n\nprint(f''\\n=== RACCOMANDAZIONI ==='')\nprint(''- File fino a 1000 righe: Performance ottimale'')  \nprint(''- File 1000-5000 righe: Buone performance, possibile rallentamento'')\nprint(''- File 5000-10000 righe: Funzionale ma lento, considerare paginazione'')\nprint(''- File >10000 righe: Necessaria paginazione o streaming'')\n\")",
      "Bash(\"F:\\python\\python.exe\" -c \"\nfrom data_importer import TalonDataImporter\n\n# Test sistema con file di dimensioni diverse  \nimporter = TalonDataImporter()\n\nif not importer.connect_to_database():\n    print(''Errore connessione database'')\n    exit(1)\n\nprint(''=== TEST SCALABILITÀ OTTIMIZZATA ==='')\n\n# Test con file attuale (327 righe - piccolo)\nanalysis = importer.analyze_excel_file(''uploads/20250817_174631_Cartel1.xls'')\ndf_all = importer.analyze_all_rows(''uploads/20250817_174631_Cartel1.xls'', ''Foglio1'')\n\nprint(f''File attuale: {len(df_all)} righe'')\nis_large = len(df_all) > 2000\nprint(f''Classificato come: {\"\"GRANDE\"\" if is_large else \"\"PICCOLO\"\"}'')\n\nif is_large:\n    preview_limit = 1000\n    print(f''Preview limitata a: {preview_limit} righe'')\nelse:\n    print(f''Preview completa: {len(df_all)} righe'')\n\nprint(f''\\nIl sistema può gestire file con:'')\nprint(f''- Fino a 2000 righe: Anteprima completa + performance ottimali'')\nprint(f''- Oltre 2000 righe: Anteprima campione + importazione completa'')\nprint(f''- File molto grandi (>10K): Paginazione automatica'')\n\n# Stima limiti teorici\nprint(f''\\n=== LIMITI TEORICI ==='')\nprint(f''- Memoria Python: Gestisce facilmente 100K+ righe'')\nprint(f''- Database PostgreSQL: Milioni di righe'')  \nprint(f''- Browser (preview): Ottimizzato fino a 50K righe'')\nprint(f''- Pratico consigliato: File fino a 20K righe per UX ottimale'')\n\nimporter.close_connection()\n\")",
      "Bash(\"F:\\python\\python.exe\":*)"
    ],
    "deny": [],
    "ask": []
  }
}